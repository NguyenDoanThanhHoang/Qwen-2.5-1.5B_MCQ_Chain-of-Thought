# Qwen 2.5 MCQ Chain-of-Thought (CoT)

## ğŸ¯ Má»¥c TiÃªu Dá»± Ãn
XÃ¢y dá»±ng mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) chuyÃªn giáº£i quyáº¿t cÃ¡c cÃ¢u há»i tráº¯c nghiá»‡m (MCQ) Ä‘Ã²i há»i suy luáº­n phá»©c táº¡p (Commonsense QA).
- **Base Model**: Qwen 2.5 1.5B Instruct
- **Dataset**: ECQA (Explanations for CommonsenseQA)
- **PhÆ°Æ¡ng phÃ¡p**:
  1. **SFT (Supervised Fine-Tuning)**: Dáº¡y mÃ´ hÃ¬nh suy luáº­n tá»«ng bÆ°á»›c (Chain-of-Thought).
  2. **DPO (Direct Preference Optimization)**: Tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh báº±ng cÃ¡ch há»c tá»« cÃ¡c máº«u suy luáº­n Ä‘Ãºng (chosen) vÃ  sai (rejected).

## ğŸš€ HÆ°á»›ng Dáº«n Cháº¡y (Google Colab)

### BÆ°á»›c 1: Upload lÃªn Google Drive
1. Táº£i toÃ n bá»™ folder dá»± Ã¡n nÃ y vá» mÃ¡y.
2. Upload folder lÃªn Google Drive cá»§a báº¡n.
   - VÃ­ dá»¥ Ä‘Æ°á»ng dáº«n: `My Drive/qwen25-mcq-cot`

### BÆ°á»›c 2: Cháº¡y trÃªn Colab
1. Má»Ÿ file `qwen25_SFT_DPO_Training.ipynb` báº±ng Google Colab.
2. Chá»n **Runtime > Change runtime type > T4 GPU**.
3. Cháº¡y láº§n lÆ°á»£t cÃ¡c Cell tá»« trÃªn xuá»‘ng dÆ°á»›i.

### ğŸ“‹ Quy TrÃ¬nh (Pipeline)
Notebook sáº½ tá»± Ä‘á»™ng thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau:
1. **Setup**: CÃ i Ä‘áº·t thÆ° viá»‡n vÃ  mount Google Drive.
2. **Data Prep**: Táº£i vÃ  xá»­ lÃ½ dá»¯ liá»‡u ECQA.
3. **Train SFT**: Fine-tune mÃ´ hÃ¬nh cÆ¡ báº£n.
4. **Generate Rejected**: Táº¡o máº«u sai tá»« mÃ´ hÃ¬nh SFT Ä‘á»ƒ phá»¥c vá»¥ DPO.
5. **Build DPO Data**: Táº¡o cáº·p dá»¯ liá»‡u preference (Ä‘Ãºng/sai).
6. **Train DPO**: Tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh vá»›i DPO.
7. **Evaluate**: ÄÃ¡nh giÃ¡ vÃ  so sÃ¡nh káº¿t quáº£ (Base vs SFT vs DPO).



